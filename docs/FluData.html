<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Flu Data Exploration</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My Data Analysis Portfolio</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="./aboutme.html">About Me</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Projects
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="./rcoding.html">R Coding</a>
    </li>
    <li>
      <a href="./visualization.html">Visualization</a>
    </li>
    <li>
      <a href="./tidytuesday.html">Tidy Tuesday</a>
    </li>
    <li>
      <a href="./FluData.html">FluData Exploration</a>
    </li>
    <li>
      <a href="./MarbleRacingExploration.html">Marble Racing</a>
    </li>
  </ul>
</li>
<li>
  <a href="https://github.com/B-Cameron0/BrentCameron-MADA-portfolio">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Flu Data Exploration</h1>

</div>


<p>This particular exploration deals with data collected about flu symptoms, we will examine the data further, pre-process to enable less interference between our data, and tune, fit, and model with a single tree, LASSO, and random forest respectively</p>
<pre class="r"><code>#First we need to load all required packages 
library(tidyverse) #for streamlining manipulating data</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──</code></pre>
<pre><code>## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
## ✓ tibble  3.1.4     ✓ dplyr   1.0.7
## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
## ✓ readr   2.0.1     ✓ forcats 0.5.1</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(tidymodels) # for streamlining fitting data to models</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;tune&#39;:
##   method                   from   
##   required_pkgs.model_spec parsnip</code></pre>
<pre><code>## ── Attaching packages ────────────────────────────────────── tidymodels 0.1.3 ──</code></pre>
<pre><code>## ✓ broom        0.7.9      ✓ rsample      0.1.0 
## ✓ dials        0.0.10     ✓ tune         0.1.6 
## ✓ infer        1.0.0      ✓ workflows    0.2.3 
## ✓ modeldata    0.1.1      ✓ workflowsets 0.1.0 
## ✓ parsnip      0.1.7      ✓ yardstick    0.0.8 
## ✓ recipes      0.1.16</code></pre>
<pre><code>## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
## x scales::discard() masks purrr::discard()
## x dplyr::filter()   masks stats::filter()
## x recipes::fixed()  masks stringr::fixed()
## x dplyr::lag()      masks stats::lag()
## x yardstick::spec() masks readr::spec()
## x recipes::step()   masks stats::step()
## • Use tidymodels_prefer() to resolve common conflicts.</code></pre>
<pre class="r"><code>library(broom) #for cleaning up output from lm()
library(here) #for data loading/saving</code></pre>
<pre><code>## here() starts at /Users/WWBD/MADA/BrentCameron-MADA-portfolio</code></pre>
<pre class="r"><code>library(ggplot2) #for plotting
library(rpart) #for fitting tree model</code></pre>
<pre><code>## 
## Attaching package: &#39;rpart&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dials&#39;:
## 
##     prune</code></pre>
<pre class="r"><code>library(glmnet) #for fitting LASSO model</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<pre><code>## Loaded glmnet 4.1-3</code></pre>
<pre class="r"><code>library(ranger) #for fitting random forest model
library(vip)</code></pre>
<pre><code>## 
## Attaching package: &#39;vip&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:utils&#39;:
## 
##     vi</code></pre>
<pre class="r"><code>#then we need to input the location of the data
data_location &lt;- here::here(&quot;Data&quot;,&quot;processed_data&quot;,&quot;exploration.rds&quot;)

#load data. 
mydata &lt;- readRDS(data_location)

#Basic examination of our data
glimpse(mydata)</code></pre>
<pre><code>## Rows: 730
## Columns: 32
## $ SwollenLymphNodes &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…
## $ ChestCongestion   &lt;fct&gt; No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…
## $ ChillsSweats      &lt;fct&gt; No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …
## $ NasalCongestion   &lt;fct&gt; No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…
## $ CoughYN           &lt;fct&gt; Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …
## $ Sneeze            &lt;fct&gt; No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …
## $ Fatigue           &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…
## $ SubjectiveFever   &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…
## $ Headache          &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…
## $ Weakness          &lt;fct&gt; Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…
## $ WeaknessYN        &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…
## $ CoughIntensity    &lt;fct&gt; Severe, Severe, Mild, Moderate, None, Moderate, Seve…
## $ CoughYN2          &lt;fct&gt; Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…
## $ Myalgia           &lt;fct&gt; Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …
## $ MyalgiaYN         &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…
## $ RunnyNose         &lt;fct&gt; No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…
## $ AbPain            &lt;fct&gt; No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…
## $ ChestPain         &lt;fct&gt; No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …
## $ Diarrhea          &lt;fct&gt; No, No, No, No, No, Yes, No, No, No, No, No, No, No,…
## $ EyePn             &lt;fct&gt; No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…
## $ Insomnia          &lt;fct&gt; No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…
## $ ItchyEye          &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, Yes,…
## $ Nausea            &lt;fct&gt; No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…
## $ EarPn             &lt;fct&gt; No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…
## $ Hearing           &lt;fct&gt; No, Yes, No, No, No, No, No, No, No, No, No, No, No,…
## $ Pharyngitis       &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …
## $ Breathless        &lt;fct&gt; No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …
## $ ToothPn           &lt;fct&gt; No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…
## $ Vision            &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, No, …
## $ Vomit             &lt;fct&gt; No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…
## $ Wheeze            &lt;fct&gt; No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…
## $ BodyTemp          &lt;dbl&gt; 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …</code></pre>
<pre class="r"><code>###################################
#Part 1- Pre-Processing
###################################
#We will remove several variables that have yes/no versions while keeping the 
#versions of the variables that have multiple levels to reduce potential 
#confounding
mydata2 &lt;- mydata %&gt;%
  select(!c(WeaknessYN,CoughYN, CoughYN2, MyalgiaYN))

#Mydata2 now shows that the number of variables has been reduced by 4, which
#is what we want, now we will code the 3 symptom severity (ordinal) factors
#as ordered and verify the correct order of none/mild/moderate/severe
mydata3 &lt;- mydata2 %&gt;%
  mutate(Weakness = factor(Weakness, levels = c(&quot;None&quot;, &quot;Mild&quot;, &quot;Moderate&quot;,&quot;Severe&quot;), ordered = TRUE))%&gt;%
  mutate(CoughIntensity = factor(CoughIntensity, levels = c(&quot;None&quot;, &quot;Mild&quot;, &quot;Moderate&quot;,&quot;Severe&quot;), ordered = TRUE)) %&gt;%
  mutate(Myalgia = factor(Myalgia, levels = c(&quot;None&quot;, &quot;Mild&quot;, &quot;Moderate&quot;,&quot;Severe&quot;), ordered = TRUE))

#Now that we have hopefully coded the variables to be ordered we will need to 
#verify that they have been changed
is.ordered(mydata3$Weakness)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>is.ordered(mydata3$CoughIntensity)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>is.ordered(mydata3$Myalgia)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>#Now that we have ordered the variables correctly we will examine our other 
#features. Two of our variables has less than 50 observations and are thus 
#unbalanced, we will need to remove them to aid in accurate data modeling
summary(mydata3)</code></pre>
<pre><code>##  SwollenLymphNodes ChestCongestion ChillsSweats NasalCongestion Sneeze   
##  No :418           No :323         No :130      No :167         No :339  
##  Yes:312           Yes:407         Yes:600      Yes:563         Yes:391  
##                                                                          
##                                                                          
##                                                                          
##                                                                          
##  Fatigue   SubjectiveFever Headache      Weakness    CoughIntensity
##  No : 64   No :230         No :115   None    : 49   None    : 47   
##  Yes:666   Yes:500         Yes:615   Mild    :223   Mild    :154   
##                                      Moderate:338   Moderate:357   
##                                      Severe  :120   Severe  :172   
##                                                                    
##                                                                    
##      Myalgia    RunnyNose AbPain    ChestPain Diarrhea  EyePn     Insomnia 
##  None    : 79   No :211   No :639   No :497   No :631   No :617   No :315  
##  Mild    :213   Yes:519   Yes: 91   Yes:233   Yes: 99   Yes:113   Yes:415  
##  Moderate:325                                                              
##  Severe  :113                                                              
##                                                                            
##                                                                            
##  ItchyEye  Nausea    EarPn     Hearing   Pharyngitis Breathless ToothPn  
##  No :551   No :475   No :568   No :700   No :119     No :436    No :565  
##  Yes:179   Yes:255   Yes:162   Yes: 30   Yes:611     Yes:294    Yes:165  
##                                                                          
##                                                                          
##                                                                          
##                                                                          
##  Vision    Vomit     Wheeze       BodyTemp     
##  No :711   No :652   No :510   Min.   : 97.20  
##  Yes: 19   Yes: 78   Yes:220   1st Qu.: 98.20  
##                                Median : 98.50  
##                                Mean   : 98.94  
##                                3rd Qu.: 99.30  
##                                Max.   :103.10</code></pre>
<pre class="r"><code>#Hearing and VIsion both have less than 50 recorded observations in their 
#respective &quot;yes&quot; category so we will remove those two variables
#Note how we create another data set (mydata4) to allow for easier back and forth
#between data sets if needed
mydata4 &lt;- mydata3 %&gt;%
  select(!c(Hearing, Vision))</code></pre>
<p>Now let us verify that everything is correct and the variables are removed</p>
<pre class="r"><code>glimpse(mydata4)</code></pre>
<pre><code>## Rows: 730
## Columns: 26
## $ SwollenLymphNodes &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…
## $ ChestCongestion   &lt;fct&gt; No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…
## $ ChillsSweats      &lt;fct&gt; No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …
## $ NasalCongestion   &lt;fct&gt; No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…
## $ Sneeze            &lt;fct&gt; No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …
## $ Fatigue           &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…
## $ SubjectiveFever   &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…
## $ Headache          &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…
## $ Weakness          &lt;ord&gt; Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…
## $ CoughIntensity    &lt;ord&gt; Severe, Severe, Mild, Moderate, None, Moderate, Seve…
## $ Myalgia           &lt;ord&gt; Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …
## $ RunnyNose         &lt;fct&gt; No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…
## $ AbPain            &lt;fct&gt; No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…
## $ ChestPain         &lt;fct&gt; No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …
## $ Diarrhea          &lt;fct&gt; No, No, No, No, No, Yes, No, No, No, No, No, No, No,…
## $ EyePn             &lt;fct&gt; No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…
## $ Insomnia          &lt;fct&gt; No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…
## $ ItchyEye          &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, Yes,…
## $ Nausea            &lt;fct&gt; No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…
## $ EarPn             &lt;fct&gt; No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…
## $ Pharyngitis       &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …
## $ Breathless        &lt;fct&gt; No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …
## $ ToothPn           &lt;fct&gt; No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…
## $ Vomit             &lt;fct&gt; No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…
## $ Wheeze            &lt;fct&gt; No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…
## $ BodyTemp          &lt;dbl&gt; 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …</code></pre>
<p>Everything looks good, all variables that can affect our models have been removed We will rename the data to a more accessible name</p>
<pre class="r"><code>finaldata &lt;- mydata4</code></pre>
<div id="section" class="section level32">
<p class="heading"></p>
<p>#Part 2- Analysis ################################</p>
<p>Now that we have pre-processed our data we can begin our analysis, first we will set our seed</p>
<pre class="r"><code>set.seed(123)

#We will now split the data by 70% for our training data and 30% for our testing
data_split &lt;- initial_split(finaldata, prop = 7/10,#7/10 stands for 70% training
                            strata = BodyTemp) # and the rest (30%) for testing) 

#Now we will organize our sets of training and test data
train_data &lt;- training(data_split)

test_data &lt;- testing(data_split)

#We will now utilize a 5-fold cross validation, 5 times repeated, we will 
#stratify on &quot;BodyTemp&quot; for the CV folds
FoldCV5 &lt;- vfold_cv(train_data, v = 5, repeats = 5, strata = &quot;BodyTemp&quot;)

#Now we will create our recipe for our data and fitting
#We will code the categorical variables as dummy variables
recipe_bodytemp &lt;-recipe(BodyTemp ~ ., data = train_data) %&gt;%
                  step_dummy(all_nominal_predictors())</code></pre>
<div id="section-1" class="section level36">
<p class="heading"></p>
<p>#Null Model Performance ####################################</p>
<p>We need to specify our model before we start computing</p>
<pre class="r"><code>lm_model &lt;- linear_reg() %&gt;% 
             set_engine(&#39;lm&#39;) %&gt;%
             set_mode(&#39;regression&#39;)</code></pre>
<p>We will now compute the performance of a null model for our training and test data (doesn’t use any predictor information)</p>
<pre class="r"><code>#Train Data Computing
train_null_recipe &lt;- lm(BodyTemp ~ 1, data = train_data)

#Calculating RMSE
train_null_recipe %&gt;% augment(newdata = train_data) %&gt;%
                      rmse(truth = BodyTemp, estimate = .fitted)</code></pre>
<pre><code>## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard        1.21</code></pre>
<pre class="r"><code>#Test Data Computing
test_null_recipe &lt;- lm(BodyTemp ~ 1, data = test_data)

#Calculating RMSE
test_null_recipe %&gt;% augment(newdata = test_data) %&gt;%
  rmse(truth = BodyTemp, estimate = .fitted)</code></pre>
<pre><code>## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard        1.16</code></pre>
</div>
<div id="section-2" class="section level33">
<p class="heading"></p>
<p>#Model Tuning and Fitting #################################</p>
<p>We will fit a tree, LASSO model, and a random forest Our steps should be as follows… 1. Model Specification 2. Workflow Definition 3. Tuning Grid Specification 4. Tuning Using Cross- Validation and the tune_grid() function</p>
<p>#Code Used for Tree model can be found from Tidymodels Tutorial #<a href="https://www.tidymodels.org/start/tuning/" class="uri">https://www.tidymodels.org/start/tuning/</a></p>
<div id="section-3" class="section level36">
<p class="heading"></p>
<p>#TREE ####################################</p>
<pre class="r"><code>#Specify Model
tune_spec_TREE &lt;-
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune(),
  ) %&gt;%
  set_engine(&quot;rpart&quot;) %&gt;%
  set_mode(&quot;regression&quot;)
tune_spec_TREE</code></pre>
<pre><code>## Decision Tree Model Specification (regression)
## 
## Main Arguments:
##   cost_complexity = tune()
##   tree_depth = tune()
## 
## Computational engine: rpart</code></pre>
<pre class="r"><code>#We will now define the workflow for the tree 
workflow_TREE &lt;- workflow() %&gt;%
            add_model(tune_spec_TREE) %&gt;%
            add_recipe(recipe_bodytemp) #The recipe command used here is from 
#line 108 where we discuss creating a recipe for data and fitting

#We will now specify the tuning grid
grid_TREE &lt;- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = 5)
grid_TREE

#We will now tune using cross validation and the tune_grid() function
res_TREE&lt;-
  workflow_TREE %&gt;%
  tune_grid(resamples = FoldCV5 , grid = grid_TREE, metrics = metric_set(rmse))

#Now we will run the autoplot() function to look at some diagnostics
res_TREE %&gt;%
  autoplot()

#Now we will selecect the best decision tree model
TOP_TREE &lt;- res_TREE %&gt;% 
  select_best(&quot;rmse&quot;)

TOP_TREE

#Now we need to finalize the workflow
workflow_FINAL &lt;- workflow_TREE %&gt;% finalize_workflow(TOP_TREE)
workflow_FINAL

#Now we will utilize the fit() function to fit to the training data
fit_FINAL_TREE &lt;- workflow_FINAL %&gt;% last_fit(data_split)

#Now we will collect the data from our fit
fit_FINAL_TREE %&gt;% collect_metrics()

#We will also collect the predictions
pred_TREE &lt;- fit_FINAL_TREE %&gt;% collect_predictions()

#We will now make two plots, one that shows model predictions from the tuned
#model compared to actual outcomes, and one that plots residuals (RMSE)
pred_tree_plot &lt;- ggplot(data = pred_TREE, aes(x = .pred, y = BodyTemp)) + 
           geom_point() +
           labs(title = &quot;Plot Comparing Model Predictions from Tuned to Actual&quot;,
                x = &quot;Predictions&quot;, y = &quot;Outcomes&quot;)
#view the plot
pred_tree_plot

#We need to calculate our residuals before we can plot 
#Note that the residuals is the difference between our main predictor and the others
pred_TREE$residuals &lt;- pred_TREE$BodyTemp - pred_TREE$.pred

#Now we will plot our residuals
resid_tree_plot &lt;- ggplot(data= pred_TREE, aes(x=.pred , y=residuals)) + geom_point() +
                    labs(title=&quot;Plot of Residuals&quot;,
                    x=&quot;Predictions&quot;, y= &quot;Residuals&quot;)
#view the plot
resid_tree_plot 

#Now we will compare our residual plot to the null model
tree_model_performance &lt;- res_TREE %&gt;% show_best(n=1)
print(tree_model_performance)
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA</code></pre>
<pre><code>## # A tibble: 25 × 2
##    cost_complexity tree_depth
##              &lt;dbl&gt;      &lt;int&gt;
##  1    0.0000000001          1
##  2    0.0000000178          1
##  3    0.00000316            1
##  4    0.000562              1
##  5    0.1                   1
##  6    0.0000000001          4
##  7    0.0000000178          4
##  8    0.00000316            4
##  9    0.000562              4
## 10    0.1                   4
## # … with 15 more rows</code></pre>
<pre class="r"><code>NA
NA
NA
NA
NA
NA
NA
NA
NA</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code>NA
NA
NA
NA
NA
NA</code></pre>
<pre><code>## # A tibble: 1 × 3
##   cost_complexity tree_depth .config              
##             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                
## 1    0.0000000001          1 Preprocessor1_Model01</code></pre>
<pre class="r"><code>NA
NA
NA
NA</code></pre>
<pre><code>## ══ Workflow ════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: decision_tree()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 1 Recipe Step
## 
## • step_dummy()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## Decision Tree Model Specification (regression)
## 
## Main Arguments:
##   cost_complexity = 1e-10
##   tree_depth = 1
## 
## Computational engine: rpart</code></pre>
<pre class="r"><code>NA
NA
NA
NA
NA
NA</code></pre>
<pre><code>## # A tibble: 2 × 4
##   .metric .estimator .estimate .config             
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 rmse    standard    1.19     Preprocessor1_Model1
## 2 rsq     standard    0.000889 Preprocessor1_Model1</code></pre>
<pre class="r"><code>NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-8-2.png" width="672" /></p>
<pre class="r"><code>NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-8-3.png" width="672" /></p>
<pre class="r"><code>NA
NA
NA
NA</code></pre>
<pre><code>## # A tibble: 1 × 8
##   cost_complexity tree_depth .metric .estimator  mean     n std_err .config     
##             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;       
## 1    0.0000000001          1 rmse    standard    1.19    25  0.0181 Preprocesso…</code></pre>
<p>The null tree and decision tree model perform very similarly, with a null RMSE of 1.14 and a decision tree RMSE of 1.19, the decision tree model does not perform better than the null</p>
<div id="section-4" class="section level41">
<p class="heading"></p>
<p>#LASSO ######################################### #Now we will construct a LASSO model #code used from <a href="https://www.tidymodels.org/start/case-study/" class="uri">https://www.tidymodels.org/start/case-study/</a></p>
<pre class="r"><code>#We will once again start by constructing our model
lasso_model &lt;- linear_reg() %&gt;%
  set_mode(&quot;regression&quot;) %&gt;%
  set_engine(&quot;glmnet&quot;) %&gt;%
  set_args(penalty = tune(), mixture = 1) 

#Please note that mixture refers to a number between zero and one that is the 
#proportion of L1 regularization (lasso) in the model. In other, words, because
#we are using mixture = 1, we are utilizing a &quot;pure&quot; lasso model here

#We will now create our workflow
lasso_workflow &lt;-workflow() %&gt;%
  add_model(lasso_model) %&gt;%
  add_recipe(recipe_bodytemp)

#Now we will tune our LASSO model
#As our last model took a long time to run, we will utilize parallel computing
#to make it faster

library(doParallel)</code></pre>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## 
## Attaching package: &#39;foreach&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:purrr&#39;:
## 
##     accumulate, when</code></pre>
<pre><code>## Loading required package: iterators</code></pre>
<pre><code>## Loading required package: parallel</code></pre>
<pre class="r"><code>ncores = 5 #Ncores is used to select the number of cores you want to recruit
#for processing, different computers will naturally have different ideal numbers

cluster &lt;- makePSOCKcluster(5) #make PSOCKcluster stands for creating a sock
#cluster within the &#39;snow&#39; package, this allowsa for increased computing time

  registerDoParallel(5) #registers parallel backend with foreach package
  
  #Now we will create our tuning grid 
  lasso_reg_grid &lt;- tibble(penalty = 10^seq(-3, 0, length.out = 30))
  #Now we tune the model
  lasso_tune_res &lt;- lasso_workflow %&gt;%
    tune_grid(resamples = FoldCV5,
              grid = lasso_reg_grid,
              control = control_grid(save_pred = TRUE),
              metrics = metric_set(rmse))
  
#We will now turn off parallel clustering, the reason we turn the clustering off
#after each use is to prevent computations and analysis from being slowed in 
#later data analysis, fitting, modeling, etc.
  stopCluster(cluster)
  
  #We will now evaluate our LASSO model
  lasso_tune_res %&gt;% autoplot()</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>  #Now we will get the tuned model that performs best
  best_lasso &lt;- lasso_tune_res %&gt;% select_best(metric = &quot;rmse&quot;)
  #We now finalize our workflow with the best model
  best_lasso_wf &lt;- lasso_workflow  %&gt;% finalize_workflow(best_lasso)
  #We now fit our best performing model
  best_lasso_fit &lt;- best_lasso_wf %&gt;%
    fit(data = train_data)
  
  lasso_pred &lt;- predict(best_lasso_fit, train_data)
  
  #Now we will repeat our steps like the past model and plot LASSO variables as
  #function of tuning parameter
  
x &lt;- best_lasso_fit$fit$fit$fit
plot(x, &quot;lambda&quot;)</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-9-2.png" width="672" /></p>
<pre class="r"><code>#When a variable is 0 it is no longer being used in the model, thus we are using
#all variables that are only part of the best fit model
tidy(extract_fit_parsnip(best_lasso_fit)) %&gt;% filter(estimate !=0)</code></pre>
<pre><code>## # A tibble: 13 × 3
##    term                estimate penalty
##    &lt;chr&gt;                  &lt;dbl&gt;   &lt;dbl&gt;
##  1 (Intercept)         98.7      0.0574
##  2 ChestCongestion_Yes  0.0332   0.0574
##  3 ChillsSweats_Yes     0.0894   0.0574
##  4 NasalCongestion_Yes -0.140    0.0574
##  5 Sneeze_Yes          -0.391    0.0574
##  6 Fatigue_Yes          0.178    0.0574
##  7 SubjectiveFever_Yes  0.377    0.0574
##  8 Weakness_1           0.178    0.0574
##  9 Myalgia_2           -0.00994  0.0574
## 10 Myalgia_3            0.0679   0.0574
## 11 RunnyNose_Yes       -0.0825   0.0574
## 12 Nausea_Yes           0.00349  0.0574
## 13 Pharyngitis_Yes      0.148    0.0574</code></pre>
<pre class="r"><code>#Now we plot the observed/predicted and residual plots
#We will try a new way to plot that does not require calculating the 
#residuals before hand

#First we will plot with the observe/predicted values
#This code will plot a line with which we hope to see overlap with 
#the values, thus signaling that the model is a good fit

#For our x and y limits, the values 97 and 103 were chosen because they allow for
#the clearest illustration of the values in the plane
#The abline is used to add lines to the graph 
plot(lasso_pred$.pred,train_data$BodyTemp, xlim = c(97, 103), ylim = c(97, 103))
abline(a = 0, b = 1, col = &#39;red&#39;) #b = 1 creates a 45 degree diagonal line</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-9-3.png" width="672" /></p>
<pre class="r"><code>#Now our residual plot, note that because we are subtracting the two values 
#used this time instead of putting them together, since residuals are by 
#definition the difference between the regular predictors and the chosen predictor
plot(lasso_pred$.pred-train_data$BodyTemp)
abline(a=0, b=0, col = &#39;blue&#39;) #b = 0 creates a straight horizontal line</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-9-4.png" width="672" /></p>
<pre class="r"><code>#Similarly to the tree model, neither the observed/predictors plot or the 
#residuals plot indicates that there is significant alignment with the data
#meaning that this model is also not significant.

#Let&#39;s look at the performance of the model directly to check this
lasso_performance &lt;- lasso_tune_res %&gt;%
                        show_best(n = 1)

print(lasso_performance)</code></pre>
<pre><code>## # A tibble: 1 × 7
##   penalty .metric .estimator  mean     n std_err .config              
##     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
## 1  0.0574 rmse    standard    1.15    25  0.0169 Preprocessor1_Model18</code></pre>
<p>The mean RMSE is 1.17, which is still not very impressive, a much lower value would be preferred</p>
</div>
</div>
</div>
</div>
<div id="section-5" class="section level32">
<p class="heading"></p>
<p>#RANDOMFOREST ################################</p>
<p>Both of our past models have not shown significant fit, we will now repeat the steps with a random forest model in the hopes of finding significance</p>
<p><em>Please note that for Random Forest models, “num.threads” and importance is required or else all models will fail</em></p>
<pre class="r"><code>randomforest_model &lt;- rand_forest() %&gt;%
  set_args(mtry = tune(),
  trees = tune(), 
  min_n = tune()
  ) %&gt;%
  #Now we set the engine
  set_engine(&quot;ranger&quot;, 
             num.threads = 5,
             importance = &quot;permutation&quot;) %&gt;%
  #We select either the continuous or binary classification
  set_mode(&quot;regression&quot;)

#We will set our workflow once again
randomforest_workflow &lt;- workflow() %&gt;% 
  add_model(randomforest_model) %&gt;%
  add_recipe(recipe_bodytemp)

#We will now repeat our steps as the first two models to specify our tuning grid
#We will use parallel computing once again to vastly decrease the time it takes 
#to compute the model- since we have already use code previously to create it
#we now only need to use our name designation for our cluster and it will resume
cluster &lt;-makePSOCKcluster(5)
registerDoParallel(5)

#Now we will tune the grid
randomforest_grid &lt;- expand.grid(mtry = c(3, 4, 5, 6), min_n = c(40, 50, 60),
                                 trees = c(500, 1000))

#We will now tune the model while optimizing RMSE
randomforest_tune_res &lt;- randomforest_workflow %&gt;%
    tune_grid(resamples = FoldCV5, #This is the name of our previous CV object
              grid = randomforest_grid,#This is the grid of values we want to try
              metrics = metric_set(rmse))

#Now we turn off our parallel clustering again to prevent slowing processing
stopCluster(cluster)

#Now we plot the performance of our different tuning parameters
randomforest_tune_res %&gt;% autoplot()</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="r"><code>#Now we will obtain the best performing model
best_randomforest &lt;- randomforest_tune_res %&gt;% select_best(metric = &quot;rmse&quot;)

#Finalize the workflow with this model
best_randomforest_workflow &lt;- randomforest_workflow %&gt;% finalize_workflow(best_randomforest)

#Now we fit the best performing model
best_randomforest_fit &lt;- best_randomforest_workflow %&gt;% fit(data = train_data)
randomforest_predict &lt;-predict(best_randomforest_fit, train_data)

#although all variables stay in a random forest model, we can examine which are 
#the most imoportant using the &#39;vip&#39; package
x&lt;- best_randomforest_fit$fit$fit$fit

#plot the variables by importance
vip(x, num_features = 26)</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-10-2.png" width="672" /></p>
<pre class="r"><code>#as can be seen from the plot, subjective fever is the most important variable
#followed by sneezing 

#We will now plot the observed/ predicted and residual plots and compare them
#we will repeat the same process used as last time
plot(randomforest_predict$.pred,train_data$BodyTemp, 
     xlim =c(97, 103), ylim=c(97, 103),
     abline(a = 0, b = 1, col = &#39;red&#39;))</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-10-3.png" width="672" /></p>
<pre class="r"><code>#residual plot
plot(randomforest_predict$.pred-train_data$BodyTemp)
     abline(a = 0, b = 0, col = &#39;blue&#39;)</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-10-4.png" width="672" /></p>
<pre class="r"><code>#now that we have finished plotting lets look at our model performance
randomforest_performance &lt;- randomforest_tune_res %&gt;% show_best(n = 1)
print(randomforest_performance)</code></pre>
<pre><code>## # A tibble: 1 × 9
##    mtry trees min_n .metric .estimator  mean     n std_err .config              
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
## 1     6   500    60 rmse    standard    1.16    25  0.0167 Preprocessor1_Model12</code></pre>
<p>The mean RMSE is 1.18, which is still not significant</p>
<p>The LASSO model had the lowest RMSE, which even though is not significant compared to the null model, still puts in in a position to be chosen as the most meaningful</p>
<div id="section-6" class="section level40">
<p class="heading"></p>
<p>#final model (LASSO) fitting ########################################</p>
<pre class="r"><code>#lets restart our parallel processing
cluster&lt;- makePSOCKcluster(5)
registerDoParallel(5)

#Now we will fit on the training set evaluating with the test data
LASSO_fit_final &lt;-best_lasso_wf %&gt;% last_fit(data_split)

#We will now use a trained workflow to predict using our 
#test data
final_test_performance&lt;-LASSO_fit_final %&gt;% collect_predictions()
print(final_test_performance)</code></pre>
<pre><code>## # A tibble: 222 × 5
##    id               .pred  .row BodyTemp .config             
##    &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               
##  1 train/test split  99.4     2    100.  Preprocessor1_Model1
##  2 train/test split  99.0     4     98.8 Preprocessor1_Model1
##  3 train/test split  99.5    11     98.2 Preprocessor1_Model1
##  4 train/test split  99.5    12     97.9 Preprocessor1_Model1
##  5 train/test split  99.0    14    102.  Preprocessor1_Model1
##  6 train/test split  99.2    17     99.3 Preprocessor1_Model1
##  7 train/test split  99.4    25     97.8 Preprocessor1_Model1
##  8 train/test split  99.4    27     99.5 Preprocessor1_Model1
##  9 train/test split  99.4    29     99.7 Preprocessor1_Model1
## 10 train/test split  99.3    32     98.8 Preprocessor1_Model1
## # … with 212 more rows</code></pre>
<pre class="r"><code>final_test_performance_RMSE &lt;- LASSO_fit_final %&gt;% collect_metrics()
print(final_test_performance_RMSE)</code></pre>
<pre><code>## # A tibble: 2 × 4
##   .metric .estimator .estimate .config             
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 rmse    standard      1.15   Preprocessor1_Model1
## 2 rsq     standard      0.0291 Preprocessor1_Model1</code></pre>
<pre class="r"><code>#When comparing the prediction of our final model with the actual data, it 
#appears to be rather close, which indicates that we thankfully avoided 
#overfitting the data

#unfortunately, when we examine the RMSE of our data we can see that it performs
#exactly the same as with the last data. While this shows the model is consistent
#it still indicates that the model is not an adequate fit for our data

#We will finally plot our final models predicted compared with observed values
#and another plot for residuals

#predicted versus observed 
plot(final_test_performance$.pred, test_data$BodyTemp, 
     xlim = c (97, 103), ylim = c(97, 103))
     abline(a = 0, b = 1, col = &#39;red&#39;)</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>#residual plot
plot(final_test_performance$.pred-test_data$BodyTemp)
     abline(a = 0, b = 0, col = &#39;red&#39;)</code></pre>
<p><img src="FluData_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
